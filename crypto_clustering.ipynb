{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a01bfd4c",
   "metadata": {},
   "source": [
    "\n",
    "# CryptoClustering Analysis\n",
    "\n",
    "In this notebook, we will analyze and cluster cryptocurrencies based on their price changes across various timeframes using **K-means clustering** and **Principal Component Analysis (PCA)**. \n",
    "\n",
    "### Objectives\n",
    "- Normalize cryptocurrency data.\n",
    "- Use the elbow method to find the optimal number of clusters.\n",
    "- Perform K-means clustering on the original data and PCA-reduced data.\n",
    "- Compare clustering results and determine feature weights.\n",
    "\n",
    "### Dataset Description\n",
    "The dataset includes the following price change percentages:\n",
    "- 24 hours (`price_change_percentage_24h`)\n",
    "- 7 days (`price_change_percentage_7d`)\n",
    "- 30 days (`price_change_percentage_30d`)\n",
    "- 60 days (`price_change_percentage_60d`)\n",
    "- 200 days (`price_change_percentage_200d`)\n",
    "- 1 year (`price_change_percentage_1y`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"crypto_market_data.csv\"\n",
    "crypto_data = pd.read_csv(file_path, index_col=\"coin_id\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(crypto_data.describe())\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(crypto_data)\n",
    "\n",
    "# Create a DataFrame with the scaled data\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=crypto_data.columns, index=crypto_data.index)\n",
    "\n",
    "# Display the first five rows of the scaled data\n",
    "print(\"First five rows of the scaled data:\")\n",
    "print(scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Find the best k using the elbow method\n",
    "k_values = range(1, 12)\n",
    "inertia = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "    kmeans.fit(scaled_df)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow Method to Determine Optimal k\")\n",
    "plt.show()\n",
    "\n",
    "# Based on the elbow curve, choose the best value for k\n",
    "best_k = int(input(\"Enter the best value for k based on the elbow curve: \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b73b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform K-means clustering with the best k\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=1)\n",
    "crypto_data[\"Cluster\"] = kmeans.fit_predict(scaled_df)\n",
    "\n",
    "# Visualize the clusters\n",
    "crypto_data.plot.scatter(x=\"price_change_percentage_24h\", \n",
    "                         y=\"price_change_percentage_7d\", \n",
    "                         c=\"Cluster\", \n",
    "                         colormap=\"viridis\", \n",
    "                         title=\"Cryptocurrency Clusters (Original Data)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA to reduce dimensions to 3 principal components\n",
    "pca = PCA(n_components=3)\n",
    "pca_data = pca.fit_transform(scaled_df)\n",
    "\n",
    "# Create a DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(pca_data, columns=[\"PC1\", \"PC2\", \"PC3\"], index=scaled_df.index)\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_.sum()\n",
    "print(f\"Total explained variance by 3 components: {explained_variance:.2f}\")\n",
    "\n",
    "# Perform K-means clustering on PCA-reduced data\n",
    "kmeans_pca = KMeans(n_clusters=best_k, random_state=1)\n",
    "pca_df[\"Cluster\"] = kmeans_pca.fit_predict(pca_df)\n",
    "\n",
    "# Visualize clusters using PCA-reduced data\n",
    "pca_df.plot.scatter(x=\"PC1\", y=\"PC2\", c=\"Cluster\", colormap=\"viridis\", title=\"Clusters (PCA Data)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe72212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the feature weights for each principal component\n",
    "weights = pd.DataFrame(pca.components_, columns=scaled_df.columns, index=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "print(\"Feature weights for each principal component:\")\n",
    "print(weights)\n",
    "\n",
    "# Identify the strongest positive/negative influences\n",
    "print(\"Strongest influences on each component:\")\n",
    "for pc in weights.index:\n",
    "    print(f\"{pc}:\")\n",
    "    print(weights.loc[pc].sort_values(ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
